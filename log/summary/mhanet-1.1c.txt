Model: "model"
__________________________________________________________________________________________________
 Layer (type)                Output Shape                 Param #   Connected to                  
==================================================================================================
 inp (InputLayer)            [(None, None, 257)]          0         []                            
                                                                                                  
 conv1d (Conv1D)             (None, None, 256)            65792     ['inp[0][0]']                 
                                                                                                  
 layer_normalization (Layer  (None, None, 256)            512       ['conv1d[0][0]']              
 Normalization)                                                                                   
                                                                                                  
 re_lu (ReLU)                (None, None, 256)            0         ['layer_normalization[0][0]'] 
                                                                                                  
 tf.compat.v1.shape (TFOpLa  (3,)                         0         ['re_lu[0][0]']               
 mbda)                                                                                            
                                                                                                  
 tf.__operators__.getitem (  ()                           0         ['tf.compat.v1.shape[0][0]']  
 SlicingOpLambda)                                                                                 
                                                                                                  
 tf.compat.v1.shape_1 (TFOp  (3,)                         0         ['re_lu[0][0]']               
 Lambda)                                                                                          
                                                                                                  
 tf.range (TFOpLambda)       (None,)                      0         ['tf.__operators__.getitem[0][
                                                                    0]']                          
                                                                                                  
 tf.__operators__.getitem_1  ()                           0         ['tf.compat.v1.shape_1[0][0]']
  (SlicingOpLambda)                                                                               
                                                                                                  
 tf.tile (TFOpLambda)        (None, None)                 0         ['tf.range[0][0]',            
                                                                     'tf.__operators__.getitem_1[0
                                                                    ][0]']                        
                                                                                                  
 embedding (Embedding)       (None, None, 256)            524288    ['tf.tile[0][0]']             
                                                                                                  
 add (Add)                   (None, None, 256)            0         ['re_lu[0][0]',               
                                                                     'embedding[0][0]']           
                                                                                                  
 attention_mask_v2 (Attenti  (None, 1, None, None)        0         ['inp[0][0]']                 
 onMaskV2)                                                                                        
                                                                                                  
 multi_head_attention (Mult  (None, None, 256)            262144    ['add[0][0]',                 
 iHeadAttention)                                                     'add[0][0]',                 
                                                                     'add[0][0]',                 
                                                                     'attention_mask_v2[0][0]']   
                                                                                                  
 add_1 (Add)                 (None, None, 256)            0         ['add[0][0]',                 
                                                                     'multi_head_attention[0][0]']
                                                                                                  
 layer_normalization_1 (Lay  (None, None, 256)            512       ['add_1[0][0]']               
 erNormalization)                                                                                 
                                                                                                  
 conv1d_1 (Conv1D)           (None, None, 1024)           263168    ['layer_normalization_1[0][0]'
                                                                    ]                             
                                                                                                  
 re_lu_1 (ReLU)              (None, None, 1024)           0         ['conv1d_1[0][0]']            
                                                                                                  
 conv1d_2 (Conv1D)           (None, None, 256)            262400    ['re_lu_1[0][0]']             
                                                                                                  
 add_2 (Add)                 (None, None, 256)            0         ['layer_normalization_1[0][0]'
                                                                    , 'conv1d_2[0][0]']           
                                                                                                  
 layer_normalization_2 (Lay  (None, None, 256)            512       ['add_2[0][0]']               
 erNormalization)                                                                                 
                                                                                                  
 multi_head_attention_1 (Mu  (None, None, 256)            262144    ['layer_normalization_2[0][0]'
 ltiHeadAttention)                                                  , 'layer_normalization_2[0][0]
                                                                    ',                            
                                                                     'layer_normalization_2[0][0]'
                                                                    , 'attention_mask_v2[0][0]']  
                                                                                                  
 add_3 (Add)                 (None, None, 256)            0         ['layer_normalization_2[0][0]'
                                                                    , 'multi_head_attention_1[0][0
                                                                    ]']                           
                                                                                                  
 layer_normalization_3 (Lay  (None, None, 256)            512       ['add_3[0][0]']               
 erNormalization)                                                                                 
                                                                                                  
 conv1d_3 (Conv1D)           (None, None, 1024)           263168    ['layer_normalization_3[0][0]'
                                                                    ]                             
                                                                                                  
 re_lu_2 (ReLU)              (None, None, 1024)           0         ['conv1d_3[0][0]']            
                                                                                                  
 conv1d_4 (Conv1D)           (None, None, 256)            262400    ['re_lu_2[0][0]']             
                                                                                                  
 add_4 (Add)                 (None, None, 256)            0         ['layer_normalization_3[0][0]'
                                                                    , 'conv1d_4[0][0]']           
                                                                                                  
 layer_normalization_4 (Lay  (None, None, 256)            512       ['add_4[0][0]']               
 erNormalization)                                                                                 
                                                                                                  
 multi_head_attention_2 (Mu  (None, None, 256)            262144    ['layer_normalization_4[0][0]'
 ltiHeadAttention)                                                  , 'layer_normalization_4[0][0]
                                                                    ',                            
                                                                     'layer_normalization_4[0][0]'
                                                                    , 'attention_mask_v2[0][0]']  
                                                                                                  
 add_5 (Add)                 (None, None, 256)            0         ['layer_normalization_4[0][0]'
                                                                    , 'multi_head_attention_2[0][0
                                                                    ]']                           
                                                                                                  
 layer_normalization_5 (Lay  (None, None, 256)            512       ['add_5[0][0]']               
 erNormalization)                                                                                 
                                                                                                  
 conv1d_5 (Conv1D)           (None, None, 1024)           263168    ['layer_normalization_5[0][0]'
                                                                    ]                             
                                                                                                  
 re_lu_3 (ReLU)              (None, None, 1024)           0         ['conv1d_5[0][0]']            
                                                                                                  
 conv1d_6 (Conv1D)           (None, None, 256)            262400    ['re_lu_3[0][0]']             
                                                                                                  
 add_6 (Add)                 (None, None, 256)            0         ['layer_normalization_5[0][0]'
                                                                    , 'conv1d_6[0][0]']           
                                                                                                  
 layer_normalization_6 (Lay  (None, None, 256)            512       ['add_6[0][0]']               
 erNormalization)                                                                                 
                                                                                                  
 multi_head_attention_3 (Mu  (None, None, 256)            262144    ['layer_normalization_6[0][0]'
 ltiHeadAttention)                                                  , 'layer_normalization_6[0][0]
                                                                    ',                            
                                                                     'layer_normalization_6[0][0]'
                                                                    , 'attention_mask_v2[0][0]']  
                                                                                                  
 add_7 (Add)                 (None, None, 256)            0         ['layer_normalization_6[0][0]'
                                                                    , 'multi_head_attention_3[0][0
                                                                    ]']                           
                                                                                                  
 layer_normalization_7 (Lay  (None, None, 256)            512       ['add_7[0][0]']               
 erNormalization)                                                                                 
                                                                                                  
 conv1d_7 (Conv1D)           (None, None, 1024)           263168    ['layer_normalization_7[0][0]'
                                                                    ]                             
                                                                                                  
 re_lu_4 (ReLU)              (None, None, 1024)           0         ['conv1d_7[0][0]']            
                                                                                                  
 conv1d_8 (Conv1D)           (None, None, 256)            262400    ['re_lu_4[0][0]']             
                                                                                                  
 add_8 (Add)                 (None, None, 256)            0         ['layer_normalization_7[0][0]'
                                                                    , 'conv1d_8[0][0]']           
                                                                                                  
 layer_normalization_8 (Lay  (None, None, 256)            512       ['add_8[0][0]']               
 erNormalization)                                                                                 
                                                                                                  
 multi_head_attention_4 (Mu  (None, None, 256)            262144    ['layer_normalization_8[0][0]'
 ltiHeadAttention)                                                  , 'layer_normalization_8[0][0]
                                                                    ',                            
                                                                     'layer_normalization_8[0][0]'
                                                                    , 'attention_mask_v2[0][0]']  
                                                                                                  
 add_9 (Add)                 (None, None, 256)            0         ['layer_normalization_8[0][0]'
                                                                    , 'multi_head_attention_4[0][0
                                                                    ]']                           
                                                                                                  
 layer_normalization_9 (Lay  (None, None, 256)            512       ['add_9[0][0]']               
 erNormalization)                                                                                 
                                                                                                  
 conv1d_9 (Conv1D)           (None, None, 1024)           263168    ['layer_normalization_9[0][0]'
                                                                    ]                             
                                                                                                  
 re_lu_5 (ReLU)              (None, None, 1024)           0         ['conv1d_9[0][0]']            
                                                                                                  
 conv1d_10 (Conv1D)          (None, None, 256)            262400    ['re_lu_5[0][0]']             
                                                                                                  
 add_10 (Add)                (None, None, 256)            0         ['layer_normalization_9[0][0]'
                                                                    , 'conv1d_10[0][0]']          
                                                                                                  
 layer_normalization_10 (La  (None, None, 256)            512       ['add_10[0][0]']              
 yerNormalization)                                                                                
                                                                                                  
 conv1d_11 (Conv1D)          (None, None, 257)            66049     ['layer_normalization_10[0][0]
                                                                    ']                            
                                                                                                  
 activation (Activation)     (None, None, 257)            0         ['conv1d_11[0][0]']           
                                                                                                  
==================================================================================================
Total params: 4600321 (17.55 MB)
Trainable params: 4600321 (17.55 MB)
Non-trainable params: 0 (0.00 Byte)
__________________________________________________________________________________________________
